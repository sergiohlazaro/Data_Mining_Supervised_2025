# ğŸ“Š MinerÃ­a de Datos: ClasificaciÃ³n Supervisada

## ğŸ“ Estructura del proyecto
# â”œâ”€â”€ imgs1/
# â”‚ â”œâ”€â”€ eda/
# â”‚ â”œâ”€â”€ seleccion_variables/
# â”‚ â”œâ”€â”€ modelos_supervisados/
# â”‚ â”œâ”€â”€ j48_smote/
# â”‚ â”œâ”€â”€ random_forest/
# â”‚ â”œâ”€â”€ combinados/
# â”‚ â””â”€â”€ fss/
# â”œâ”€â”€ resultados/
# â”‚ â”œâ”€â”€ seleccion_variables/
# â”‚ â”œâ”€â”€ modelos_supervisados/
# â”‚ â”œâ”€â”€ j48_smote/
# â”‚ â”œâ”€â”€ random_forest/
# â”‚ â”œâ”€â”€ combinados/
# â”‚ â”œâ”€â”€ fss/
# â”‚ â””â”€â”€ resumen/
# â”œâ”€â”€ mlb_teams.csv
# â””â”€â”€ script_trabajo1.py


---

## âœ… Objetivos

- Cargar y analizar un dataset con caracterÃ­sticas suficientes.
- Preprocesar los datos de manera adecuada.
- Seleccionar variables mediante anÃ¡lisis univariante y multivariante.
- Aplicar mÃºltiples modelos supervisados.
- Comparar resultados e interpretar modelos transparentes.
- Aplicar tÃ©cnicas de balanceo y combinaciones de clasificadores.
- Generar visualizaciones y consolidar los resultados.

---

## ğŸ“„ Dataset

Se ha utilizado un dataset con informaciÃ³n histÃ³rica de los equipos de bÃ©isbol de la MLB, incluyendo estadÃ­sticas de temporada y resultados.

- Observaciones: 2784
- Variables: 39 (despuÃ©s del preprocesado)
- Targets: 
  - `division_winner`
  - `league_winner`
  - `world_series_winner`

---

## âš™ï¸ Proceso desarrollado

### 1. AnÃ¡lisis Exploratorio (EDA)
- Porcentaje de valores nulos.
- EstadÃ­sticas descriptivas.
- Matriz de correlaciÃ³n.
- Visualizaciones guardadas en `imgs1/eda`.

### 2. Preprocesamiento
- ImputaciÃ³n de valores nulos.
- CodificaciÃ³n de variables categÃ³ricas.
- Limpieza de columnas irrelevantes.

### 3. SelecciÃ³n de Variables
- **Univariante**: Mutual Information y ChiÂ².
- **Multivariante (FSS)**:
  - Filtrado por importancia (Random Forest).
  - Wrapper con RFE + RegresiÃ³n LogÃ­stica.

### 4. Modelado Supervisado
Modelos aplicados:
- KNN (k=1, k=3)
- Naive Bayes
- Ãrbol de decisiÃ³n (entropy)
- Ãrbol tipo J48 (con poda)
- RegresiÃ³n LogÃ­stica

### 5. TÃ©cnicas Avanzadas
- Ãrbol con **SMOTE** para datos desbalanceados.
- **Random Forest** con 100 Ã¡rboles.
- **Modelos combinados**: Voting y Stacking.

### 6. InterpretaciÃ³n de Modelos Transparentes
- **JRip**: Reglas inferidas.
- **Ãrboles**: Condiciones y caminos de decisiÃ³n.
- **RegresiÃ³n logÃ­stica**: Coeficientes y efecto de variables.
- **TAN**: Supuesto razonado de estructura y evaluaciÃ³n.

---

## ğŸ“ˆ Resultados

Los resultados se consolidan en `resultados/resumen/resumen_modelos.csv` e incluyen:

- Accuracy
- F1 Score
- PrecisiÃ³n
- Recall

GrÃ¡ficos comparativos generados automÃ¡ticamente para cada mÃ©trica y target.

---

## ğŸ” Conclusiones

- El dataset ha sido procesado correctamente y se han cumplido los requisitos de la prÃ¡ctica.
- Los modelos como **Random Forest**, **Ãrboles de decisiÃ³n** y **StackingClassifier** han mostrado el mejor rendimiento.
- Se ha trabajado con mÃ©tricas relevantes para clases desbalanceadas.
- Todos los resultados han sido visualizados y exportados correctamente.

---

## ğŸ§  Requisitos de la prÃ¡ctica cubiertos

- âœ… Carga, anÃ¡lisis y limpieza de datos.
- âœ… Preprocesamiento completo.
- âœ… SelecciÃ³n de variables (univariante y multivariante).
- âœ… Modelado con mÃºltiples algoritmos.
- âœ… EvaluaciÃ³n y comparaciÃ³n de resultados.
- âœ… InterpretaciÃ³n de modelos transparentes.
- âœ… AplicaciÃ³n de tÃ©cnicas avanzadas: SMOTE, combinados.
- âœ… VisualizaciÃ³n, exportaciÃ³n de resultados y estructura de carpetas.

---

## ğŸš€ EjecuciÃ³n

Para ejecutar el script:

```bash
python script_trabajo1.py

---

