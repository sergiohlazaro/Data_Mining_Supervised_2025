# Mineria de Datos

## ğŸ“Œ DescripciÃ³n del Proyecto
Este proyecto tiene como objetivo la experimentaciÃ³n con distintos **modelos de clasificaciÃ³n supervisada** en el contexto de **MinerÃ­a de Datos**. Se ha aplicado un enfoque de **preprocesamiento de datos, selecciÃ³n de variables, optimizaciÃ³n de hiperparÃ¡metros y combinaciÃ³n de modelos** para determinar cuÃ¡l ofrece el mejor rendimiento.

---
## ğŸ“‚ Estructura del Proyecto

```
ğŸ“ Mineria_de_Datos_Proyecto
â”‚-- ğŸ“„ script_trabajo1_v1.py  # VersiÃ³n inicial con modelos bÃ¡sicos
â”‚-- ğŸ“„ script_trabajo1_v2.py  # Ajustes en el preprocesamiento de datos
â”‚-- ğŸ“„ script_trabajo1_v3.py  # Balanceo de clases con SMOTE
â”‚-- ğŸ“„ script_trabajo1_v4.py  # SelecciÃ³n de variables
â”‚-- ğŸ“„ script_trabajo1_v5.py  # ImplementaciÃ³n de validaciÃ³n cruzada
â”‚-- ğŸ“„ script_trabajo1_v6.py  # OptimizaciÃ³n de hiperparÃ¡metros
â”‚-- ğŸ“„ script_trabajo1_v7.py  # CombinaciÃ³n de modelos
â”‚-- ğŸ“„ script_trabajo1_v8.py  # Modelos finales y comparaciÃ³n
â”‚-- ğŸ“„ README.md  # DocumentaciÃ³n del proyecto
â”‚-- ğŸ“ imgs1/   # Carpeta con imÃ¡genes generadas
â”‚   â”œâ”€â”€ incidents.byCountryYr.csv  # Dataset de incidentes
â”‚-- ğŸ“ documentation/  # Resultados, documentos...
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ ...
```

---
## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### **ğŸ“¦ Requerimientos**
AsegÃºrate de tener **Python 3.9 o superior** instalado junto con las siguientes librerÃ­as:
```bash
pip install numpy pandas matplotlib seaborn scikit-learn imbalanced-learn
```

### **ğŸ“‚ Uso**
1. **Descargar el repositorio**
```bash
git clone https://github.com/tu_usuario/mineria_de_datos.git
cd mineria_de_datos
```
2. **Ejecutar un script especÃ­fico**
```bash
python script_trabajo1_v1.py
```
3. **Explorar resultados** en la terminal.

---
## ğŸ“Š Modelos Utilizados
A continuaciÃ³n, se listan algunos de los modelos implementados, junto con sus resultados **antes y despuÃ©s de la optimizaciÃ³n**:

### **ğŸ“Œ Algoritmos de ClasificaciÃ³n**
| Modelo | Accuracy (Inicial) | Accuracy (Optimizado) |
|--------|-------------------|----------------------|
| IB1 (k=1) | 56.66% | 56.22% |
| IBk (k=3) | 57.40% | 64.26% |
| Naive Bayes | 36.17% | 23.77% |
| Ãrbol de DecisiÃ³n (ID3) | 62.30% | 57.69% |
| J48 (ID3 con poda) | 45.49% | N/A |
| RegresiÃ³n LogÃ­stica | 37.99% | 19.65% |
| JRip (Reglas RIPPER - WEKA) | 60.11% | N/A |
| Voting Classifier | 60.78% | 63.28% |
| Stacking Classifier | 58.33% | 57.01% |

âœ… **Mejor modelo final:** **Weighted Voting Classifier** (Accuracy **63.77%**)

---
## ğŸ“Œ SelecciÃ³n de Variables
Se implementaron distintos mÃ©todos para reducir la dimensionalidad del dataset:
- **Filtrado Univariante**: Chi-cuadrado y Mutual Information.
- **Wrapper Methods**: Recursive Feature Elimination (RFE), Sequential Feature Selection (SFS).
- **Embedded Methods**: Random Forest Feature Importance, Lasso Regression.

ğŸ” **Resultados:**
- **Eliminar `iyear` afectÃ³ negativamente a Naive Bayes y RegresiÃ³n LogÃ­stica**.
- **ID3 y k-NN mantuvieron su rendimiento tras la selecciÃ³n de variables**.

---
## ğŸ”§ OptimizaciÃ³n de Modelos
Se utilizaron tÃ©cnicas como `GridSearchCV` para ajustar hiperparÃ¡metros:

| Modelo | Mejores HiperparÃ¡metros |
|--------|------------------------|
| k-NN | `n_neighbors=3`, `weights='uniform'` |
| Ãrbol de DecisiÃ³n (ID3) | `max_depth=None`, `min_samples_split=2` |
| Naive Bayes | `var_smoothing=1.0` |
| RegresiÃ³n LogÃ­stica | `C=0.0001`, `solver='lbfgs'` |

**Impacto:** La optimizaciÃ³n mejorÃ³ k-NN e ID3, pero **Naive Bayes y RegresiÃ³n LogÃ­stica no se beneficiaron**.

---
## ğŸ“Š ValidaciÃ³n del Modelo
Se aplicÃ³ **ValidaciÃ³n Cruzada k-Fold (k=5)** para evaluar la estabilidad de los modelos:

```python
from sklearn.model_selection import cross_val_score
scores = cross_val_score(knn_model, X_train_bal, y_train_bal, cv=5)
```

âœ… **Mejor rendimiento en validaciÃ³n cruzada:**
- **k-NN: 49.75% accuracy promedio**.
- **Voting Classifier superÃ³ el 60% tras la validaciÃ³n**.

---
## ğŸ”„ CombinaciÃ³n de Modelos
Se probaron combinaciones de modelos para mejorar la precisiÃ³n final:

| Modelo Combinado | Accuracy Final |
|-----------------|---------------|
| **Voting Classifier** | **63.28%** |
| **Stacking Classifier** (RegresiÃ³n LogÃ­stica) | **59.31%** |
| **Weighted Voting Classifier** | **63.77%** âœ… Mejor opciÃ³n |

ğŸ“Œ **ConclusiÃ³n:** La combinaciÃ³n de modelos mejorÃ³ el rendimiento, destacando **Weighted Voting Classifier como el mejor modelo**.

---
## ğŸ“Œ Conclusiones
âœ… **k-NN (k=3) y Weighted Voting fueron los modelos mÃ¡s efectivos.**
âŒ **Naive Bayes y RegresiÃ³n LogÃ­stica no fueron adecuados para este dataset.**
ğŸ“Š **La combinaciÃ³n de modelos fue clave para obtener mejores resultados.**

---


