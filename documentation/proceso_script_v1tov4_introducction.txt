[ESTE ES UN BREVE RESUMEN DEL PROCESO LLEVADO A CABO HASTA EL script_trabajo1_v4.py]

ğŸ”¹ 1. Carga y exploraciÃ³n del dataset

    - Dataset: incidents.byCountryYr.csv (10200 registros, 4 columnas).
    - Variables principales:
    
        country_txt: PaÃ­s del incidente.
        iyear: AÃ±o del incidente.
        Freq: NÃºmero de incidentes en ese paÃ­s y aÃ±o.

    - Acciones realizadas:

        Cargamos los datos y verificamos si tenÃ­an valores nulos o duplicados.
        Identificamos que Freq estaba altamente desbalanceado (muchos valores 0).

    -> ğŸ“Š Diagrama de distribuciÃ³n de Freq:
            (ğŸ“Œ Histograma original, mostrando el sesgo hacia 0)

ğŸ”¹ 2. TransformaciÃ³n y preprocesamiento de los datos

    - Transformaciones aplicadas a Freq:

        TransformaciÃ³n logarÃ­tmica (log(Freq + 1)) para reducir el impacto de valores extremos.
        CategorizaciÃ³n (Bajo, Medio, Alto, Cero) usando pd.cut().
        NormalizaciÃ³n de Freq entre [0,1].

    -> ğŸ“Š Diagrama de Freq despuÃ©s de la transformaciÃ³n logarÃ­tmica:
            (ğŸ“Œ Histograma corregido con valores mÃ¡s balanceados)

ğŸ”¹ 3. DivisiÃ³n del dataset y preparaciÃ³n para modelos

    - SelecciÃ³n de variables:

        Predictoras: iyear, country_txt (convertido a numÃ©rico con LabelEncoder).
        Variable objetivo: Freq_category (Bajo, Medio, Alto, Cero).
        DivisiÃ³n en conjuntos de entrenamiento (80%) y prueba (20%).

    -> ğŸ“Š TamaÃ±o de los conjuntos de datos:

            Entrenamiento: 8160 registros.
            Prueba: 2040 registros.

ğŸ”¹ 4. Balanceo de clases con SMOTE

    - Problema detectado: Freq_category estaba desbalanceado (mucha clase "Cero").
    - SoluciÃ³n aplicada: SMOTE para generar muestras sintÃ©ticas de las clases menos representadas.

    -> ğŸ“Š TamaÃ±o despuÃ©s de SMOTE:

            Entrenamiento balanceado: 19,708 registros.

ğŸ”¹ 5. Entrenamiento de modelos de clasificaciÃ³n

    - Probamos 4 modelos de clasificaciÃ³n supervisada:

        Naive Bayes
        Ãrbol de DecisiÃ³n
        k-NN (k=3)
        RegresiÃ³n LogÃ­stica (max_iter=1000 para evitar problemas de convergencia)

ğŸ”¹ 6. EvaluaciÃ³n de los modelos

    - Para cada modelo, calculamos:

        Accuracy (precisiÃ³n global).
        Matriz de ConfusiÃ³n (errores en cada clase).
        Precision, Recall y F1-score.

        Modelo	                        Accuracy

        Naive Bayes	                    36.17%
        Ãrbol de DecisiÃ³n               âœ…62.74%
        k-NN (k=3)	                    57.40%
        RegresiÃ³n LogÃ­stica	            37.99%

        ğŸ“Œ ConclusiÃ³n:

        - Naive Bayes y RegresiÃ³n LogÃ­stica fallaron (baja precisiÃ³n en clases "Alto" y "Medio").
        - Ãrbol de DecisiÃ³n fue el mejor modelo.
        - k-NN funcionÃ³ mejor que Naive Bayes, pero sigue por debajo del Ãrbol de DecisiÃ³n.

        -> ğŸ“Š Matriz de ConfusiÃ³n del Ãrbol de DecisiÃ³n:
                (ğŸ“Œ GrÃ¡fico donde se observa que mejora en todas las clases).

ğŸš€ PrÃ³ximo paso: Implementar los modelos faltantes:

    IB1 (k-NN con k=1, sin Weka)
    TAN (Tree Augmented Naive Bayes en Weka)
    JRip (Reglas RIPPER en Weka)
    ID3 (Ãrbol de DecisiÃ³n basado en entropÃ­a, sin Weka)
    J48 (VersiÃ³n mejorada de ID3, C4.5 sin Weka)