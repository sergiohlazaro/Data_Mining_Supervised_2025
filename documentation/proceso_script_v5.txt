
Hemos probado 6 modelos de clasificaciÃ³n supervisada y ahora analizaremos sus resultados en tÃ©rminos teÃ³ricos y prÃ¡cticos. 
Nos enfocaremos en accuracy, precision, recall, f1-score y la matriz de confusiÃ³n para cada modelo.

ğŸ“Œ 1. Naive Bayes
    ğŸ“ˆ Accuracy: 36.17% (el peor modelo).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - Naive Bayes asume independencia entre las variables predictoras, lo cual no se cumple en este dataset.
    - Tiende a favorecer la clase mayoritaria ("Cero"), lo que provoca baja precisiÃ³n en las demÃ¡s clases.
    - La clase "Alto" solo tiene un 5% de precisiÃ³n, lo que indica que no se estÃ¡ clasificando bien.

    ğŸ“Š ConclusiÃ³n:
    âŒ Modelo descartado. No es adecuado para este problema debido a la fuerte dependencia entre iyear y country_txt.

ğŸ“Œ 2. Ãrbol de DecisiÃ³n (ID3)
    ğŸ“ˆ Accuracy: 62.30% (mejor que Naive Bayes y J48).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - ID3 usa la entropÃ­a para dividir los datos, lo que le permite manejar datos categÃ³ricos y continuos.
    - Mejor precisiÃ³n y recall en todas las clases en comparaciÃ³n con Naive Bayes.
    - Clase "Alto" mejora a un 37% de precisiÃ³n y 84% de recall, lo que indica que puede identificar estos casos.

    ğŸ“Š ConclusiÃ³n:
    âœ… Modelo prometedor. Puede mejorarse con poda de ramas o con un modelo mÃ¡s avanzado como Random Forest.

ğŸ“Œ 3. J48 (ID3 con poda)
    ğŸ“ˆ Accuracy: 45.49% (peor que ID3).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - J48 es ID3 mejorado con poda, lo que evita el sobreajuste.
    - Sin embargo, la poda ha reducido demasiado la capacidad predictiva del modelo.
    - Baja precisiÃ³n en la clase "Alto" y "Medio", lo que indica que el modelo se ha vuelto demasiado simple.

    ğŸ“Š ConclusiÃ³n:
    âŒ Modelo descartado en su forma actual. PodrÃ­amos probar una versiÃ³n con un ajuste de profundidad menor (max_depth=15 en vez de max_depth=10).

ğŸ“Œ 4. IB1 (k-NN con k=1)
    ğŸ“ˆ Accuracy: 56.67% (mejor que Naive Bayes y J48, pero peor que ID3).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - IB1 es un clasificador basado en instancias que usa solo el vecino mÃ¡s cercano.
    - Alto recall en la clase "Alto" (80%), pero baja precisiÃ³n (33%), lo que indica que clasifica muchos casos como "Alto" incorrectamente.
    - Mejor que J48 y Naive Bayes, pero menos estable que ID3.

    ğŸ“Š ConclusiÃ³n:
    âœ… PodrÃ­a mejorar con una mayor cantidad de vecinos (k=3 o k=5).

ğŸ“Œ 5. k-NN (k=3)
    ğŸ“ˆ Accuracy: 57.40% (mejor que IB1, pero peor que ID3).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - Usa los 3 vecinos mÃ¡s cercanos para decidir la clase, lo que reduce el impacto de valores atÃ­picos.
    - Mayor precisiÃ³n en "Alto" que IB1 (28% vs. 33%), pero menor recall (80% vs. 54%).
    - Modelo mÃ¡s estable que IB1, pero aÃºn no supera a ID3.

    ğŸ“Š ConclusiÃ³n:
    âœ… Mejor que IB1, pero podrÃ­amos probar k=5 para ver si mejora aÃºn mÃ¡s.

ğŸ“Œ 6. RegresiÃ³n LogÃ­stica
    ğŸ“ˆ Accuracy: 37.99% (similar a Naive Bayes).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - Funciona bien cuando hay una relaciÃ³n lineal entre las variables y la salida, lo que no parece cumplirse aquÃ­.
    - Baja precisiÃ³n en todas las clases excepto "Cero" (67% de precisiÃ³n, pero 50% de recall).
    - Parece favorecer la clase mayoritaria, lo que hace que clases como "Alto" y "Medio" tengan precisiÃ³n de 5% y 7% respectivamente.

    ğŸ“Š ConclusiÃ³n:
    âŒ Modelo descartado. No es adecuado para este problema.

[VAMOS A PROCEDER A AJUSTAR LOS HIPERPARÃMETROS DE LOS MODELOS MÃS PROMETEDORES]

ğŸ“Œ ConclusiÃ³n General de la OptimizaciÃ³n

    âœ… ID3 ya estaba en su mejor configuraciÃ³n, por lo que la optimizaciÃ³n no tuvo efecto.
    âŒ k-NN con weights="distance" no mejorÃ³, e incluso empeorÃ³ levemente.

ğŸ“Œ Â¿QuÃ© hacemos ahora?

    - Descartar mÃ¡s ajustes en ID3 y probar Random Forest.
    - En k-NN, probar k=5 y k=7 para ver si mejora.
    - Pasar a la selecciÃ³n de variables para ver si reduce el ruido y mejora los modelos.

ğŸ“Œ ComparaciÃ³n de Random Forest con Ãrbol de DecisiÃ³n (ID3)
ğŸ“Œ Â¿QuÃ© pasÃ³?

    - EsperÃ¡bamos que Random Forest superara ID3, pero su rendimiento es ligeramente peor.
    - Posible razÃ³n: Al usar max_depth=15, limitamos su capacidad de decisiÃ³n.
    - Sin embargo, Random Forest sigue siendo mÃ¡s robusto porque reduce el sobreajuste.

    ğŸ“Š ConclusiÃ³n sobre Random Forest: âœ… Tiene una mejor generalizaciÃ³n que ID3, pero la precisiÃ³n global no mejora.

ğŸ“Œ PodrÃ­amos probar Random Forest con max_depth=None para ver si mejora.

ğŸ“Œ ComparaciÃ³n de k-NN (k=3, k=5 y k=7)
ğŸ“Œ Â¿QuÃ© pasÃ³?

    - Aumentar k a 5 y 7 no mejorÃ³ el rendimiento, sino que lo redujo.
    - Esto indica que los puntos cercanos tienen mÃ¡s informaciÃ³n relevante, por lo que valores mÃ¡s altos de k introducen ruido.
    - El mejor k sigue siendo k=3.

    ğŸ“Š ConclusiÃ³n sobre k-NN: âœ… k=3 sigue siendo la mejor opciÃ³n.
    âŒ k=5 y k=7 reducen la precisiÃ³n, lo que indica que el modelo es mÃ¡s sensible a vecinos cercanos.

ğŸ“Œ ComparaciÃ³n de Random Forest (max_depth=15 vs. max_depth=None)
ğŸ“Œ Â¿QuÃ© pasÃ³?

    - Reducir max_depth a 15 mejoraba la generalizaciÃ³n.
    - Sin lÃ­mite de profundidad, el modelo se sobreajusta, perdiendo capacidad predictiva en datos nuevos.
    - BajÃ³ la precisiÃ³n en todas las clases, especialmente en "Cero" y "Bajo".

    ğŸ“Š ConclusiÃ³n:
    âŒ max_depth=None no es recomendable para este dataset.
    âœ… Random Forest con max_depth=15 sigue siendo mejor opciÃ³n.


ğŸ“Œ ComparaciÃ³n con ID3 (Ãrbol de DecisiÃ³n)

    ğŸ“Š ConclusiÃ³n General:
    
    1ï¸. ID3 sigue siendo el mejor modelo hasta ahora.
    2ï¸. Random Forest con max_depth=15 sigue siendo la mejor versiÃ³n de Random Forest.
    3ï¸. max_depth=None causa sobreajuste y pierde capacidad predictiva.

ğŸ”¹ Â¿Podemos mejorar Random Forest?

- PodrÃ­amos probar tres ajustes adicionales, pero hay razones para creer que no cambiarÃ¡n radicalmente los resultados:

1ï¸. Aumentar n_estimators (nÃºmero de Ã¡rboles)

ğŸ“Œ Â¿Por quÃ© podrÃ­a ayudar?

    - MÃ¡s Ã¡rboles pueden estabilizar la predicciÃ³n y reducir la varianza.
    - Sin embargo, ya estamos usando 100 Ã¡rboles, lo cual es un nÃºmero razonable.

ğŸ“Œ Â¿Por quÃ© podrÃ­a no servir?

    - El dataset no es tan grande, por lo que mÃ¡s Ã¡rboles pueden aumentar el tiempo de cÃ³mputo sin mejorar la precisiÃ³n.
    - ID3 ya estÃ¡ funcionando bien con un solo Ã¡rbol, lo que indica que Random Forest no tiene una ventaja clara en esta tarea.

2ï¸. Probar otros criterios de divisiÃ³n (criterion="gini" vs. "entropy")

ğŸ“Œ Â¿Por quÃ© podrÃ­a ayudar?

    - "gini" puede ser mÃ¡s eficiente en algunos casos.
    - "entropy" (actualmente usado) es mÃ¡s preciso en datasets con clases desbalanceadas.

ğŸ“Œ Â¿Por quÃ© podrÃ­a no servir?

    - Ya usamos "entropy" en ID3, que ha demostrado ser el mejor modelo.
    - Cambiar a "gini" rara vez produce mejoras significativas en problemas similares.

3ï¸. Probar min_samples_split y min_samples_leaf

ğŸ“Œ Â¿Por quÃ© podrÃ­a ayudar?

    - Ajustar estos valores puede hacer que el modelo aprenda menos ruido.

ğŸ“Œ Â¿Por quÃ© podrÃ­a no servir?

    - ID3 ya estÃ¡ funcionando bien sin necesidad de ajustes tan finos.
    - Si la selecciÃ³n de variables mejora el dataset, el impacto en la precisiÃ³n serÃ¡ mayor que cualquier ajuste fino en Random Forest.

ğŸ“Œ ReflexiÃ³n Final: Â¿Vale la pena seguir optimizando Random Forest?

âŒ No, no tiene sentido seguir optimizando Random Forest en este punto.
âœ… Es mÃ¡s estratÃ©gico probar la selecciÃ³n de variables y despuÃ©s ver si Random Forest mejora con un dataset mÃ¡s limpio.
