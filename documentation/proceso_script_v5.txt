
Hemos probado 6 modelos de clasificaciÃ³n supervisada y ahora analizaremos sus resultados en tÃ©rminos teÃ³ricos y prÃ¡cticos. 
Nos enfocaremos en accuracy, precision, recall, f1-score y la matriz de confusiÃ³n para cada modelo.

ğŸ“Œ 1. Naive Bayes
    ğŸ“ˆ Accuracy: 36.17% (el peor modelo).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - Naive Bayes asume independencia entre las variables predictoras, lo cual no se cumple en este dataset.
    - Tiende a favorecer la clase mayoritaria ("Cero"), lo que provoca baja precisiÃ³n en las demÃ¡s clases.
    - La clase "Alto" solo tiene un 5% de precisiÃ³n, lo que indica que no se estÃ¡ clasificando bien.

    ğŸ“Š ConclusiÃ³n:
    âŒ Modelo descartado. No es adecuado para este problema debido a la fuerte dependencia entre iyear y country_txt.

ğŸ“Œ 2. Ãrbol de DecisiÃ³n (ID3)
    ğŸ“ˆ Accuracy: 62.30% (mejor que Naive Bayes y J48).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - ID3 usa la entropÃ­a para dividir los datos, lo que le permite manejar datos categÃ³ricos y continuos.
    - Mejor precisiÃ³n y recall en todas las clases en comparaciÃ³n con Naive Bayes.
    - Clase "Alto" mejora a un 37% de precisiÃ³n y 84% de recall, lo que indica que puede identificar estos casos.

    ğŸ“Š ConclusiÃ³n:
    âœ… Modelo prometedor. Puede mejorarse con poda de ramas o con un modelo mÃ¡s avanzado como Random Forest.

ğŸ“Œ 3. J48 (ID3 con poda)
    ğŸ“ˆ Accuracy: 45.49% (peor que ID3).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - J48 es ID3 mejorado con poda, lo que evita el sobreajuste.
    - Sin embargo, la poda ha reducido demasiado la capacidad predictiva del modelo.
    - Baja precisiÃ³n en la clase "Alto" y "Medio", lo que indica que el modelo se ha vuelto demasiado simple.

    ğŸ“Š ConclusiÃ³n:
    âŒ Modelo descartado en su forma actual. PodrÃ­amos probar una versiÃ³n con un ajuste de profundidad menor (max_depth=15 en vez de max_depth=10).

ğŸ“Œ 4. IB1 (k-NN con k=1)
    ğŸ“ˆ Accuracy: 56.67% (mejor que Naive Bayes y J48, pero peor que ID3).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - IB1 es un clasificador basado en instancias que usa solo el vecino mÃ¡s cercano.
    - Alto recall en la clase "Alto" (80%), pero baja precisiÃ³n (33%), lo que indica que clasifica muchos casos como "Alto" incorrectamente.
    - Mejor que J48 y Naive Bayes, pero menos estable que ID3.

    ğŸ“Š ConclusiÃ³n:
    âœ… PodrÃ­a mejorar con una mayor cantidad de vecinos (k=3 o k=5).

ğŸ“Œ 5. k-NN (k=3)
    ğŸ“ˆ Accuracy: 57.40% (mejor que IB1, pero peor que ID3).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - Usa los 3 vecinos mÃ¡s cercanos para decidir la clase, lo que reduce el impacto de valores atÃ­picos.
    - Mayor precisiÃ³n en "Alto" que IB1 (28% vs. 33%), pero menor recall (80% vs. 54%).
    - Modelo mÃ¡s estable que IB1, pero aÃºn no supera a ID3.

    ğŸ“Š ConclusiÃ³n:
    âœ… Mejor que IB1, pero podrÃ­amos probar k=5 para ver si mejora aÃºn mÃ¡s.

ğŸ“Œ 6. RegresiÃ³n LogÃ­stica
    ğŸ“ˆ Accuracy: 37.99% (similar a Naive Bayes).

    ğŸ” InterpretaciÃ³n teÃ³rica:

    - Funciona bien cuando hay una relaciÃ³n lineal entre las variables y la salida, lo que no parece cumplirse aquÃ­.
    - Baja precisiÃ³n en todas las clases excepto "Cero" (67% de precisiÃ³n, pero 50% de recall).
    - Parece favorecer la clase mayoritaria, lo que hace que clases como "Alto" y "Medio" tengan precisiÃ³n de 5% y 7% respectivamente.

    ğŸ“Š ConclusiÃ³n:
    âŒ Modelo descartado. No es adecuado para este problema.

[VAMOS A PROCEDER A AJUSTAR LOS HIPERPARÃMETROS DE LOS MODELOS MÃS PROMETEDORES]

ğŸ“Œ ConclusiÃ³n General de la OptimizaciÃ³n

    âœ… ID3 ya estaba en su mejor configuraciÃ³n, por lo que la optimizaciÃ³n no tuvo efecto.
    âŒ k-NN con weights="distance" no mejorÃ³, e incluso empeorÃ³ levemente.

ğŸ“Œ Â¿QuÃ© hacemos ahora?

    - Descartar mÃ¡s ajustes en ID3 y probar Random Forest.
    - En k-NN, probar k=5 y k=7 para ver si mejora.
    - Pasar a la selecciÃ³n de variables para ver si reduce el ruido y mejora los modelos.

