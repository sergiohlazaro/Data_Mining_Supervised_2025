
Hemos probado 6 modelos de clasificaci√≥n supervisada y ahora analizaremos sus resultados en t√©rminos te√≥ricos y pr√°cticos. 
Nos enfocaremos en accuracy, precision, recall, f1-score y la matriz de confusi√≥n para cada modelo.

1. Naive Bayes
    Accuracy: 36.17% (el peor modelo).

    Interpretaci√≥n te√≥rica:

    - Naive Bayes asume independencia entre las variables predictoras, lo cual no se cumple en este dataset.
    - Tiende a favorecer la clase mayoritaria ("Cero"), lo que provoca baja precisi√≥n en las dem√°s clases.
    - La clase "Alto" solo tiene un 5% de precisi√≥n, lo que indica que no se est√° clasificando bien.

    Conclusi√≥n:
    Modelo descartado. No es adecuado para este problema debido a la fuerte dependencia entre iyear y country_txt.

2. √Årbol de Decisi√≥n (ID3)
    Accuracy: 62.30% (mejor que Naive Bayes y J48).

    Interpretaci√≥n te√≥rica:

    - ID3 usa la entrop√≠a para dividir los datos, lo que le permite manejar datos categ√≥ricos y continuos.
    - Mejor precisi√≥n y recall en todas las clases en comparaci√≥n con Naive Bayes.
    - Clase "Alto" mejora a un 37% de precisi√≥n y 84% de recall, lo que indica que puede identificar estos casos.

    Conclusi√≥n:
    ‚úÖ Modelo prometedor. Puede mejorarse con poda de ramas o con un modelo m√°s avanzado como Random Forest.

3. J48 (ID3 con poda)
    Accuracy: 45.49% (peor que ID3).

    Interpretaci√≥n te√≥rica:

    - J48 es ID3 mejorado con poda, lo que evita el sobreajuste.
    - Sin embargo, la poda ha reducido demasiado la capacidad predictiva del modelo.
    - Baja precisi√≥n en la clase "Alto" y "Medio", lo que indica que el modelo se ha vuelto demasiado simple.

    Conclusi√≥n:
    Modelo descartado en su forma actual. Podr√≠amos probar una versi√≥n con un ajuste de profundidad menor (max_depth=15 en vez de max_depth=10).

4. IB1 (k-NN con k=1)
    Accuracy: 56.67% (mejor que Naive Bayes y J48, pero peor que ID3).

    Interpretaci√≥n te√≥rica:

    - IB1 es un clasificador basado en instancias que usa solo el vecino m√°s cercano.
    - Alto recall en la clase "Alto" (80%), pero baja precisi√≥n (33%), lo que indica que clasifica muchos casos como "Alto" incorrectamente.
    - Mejor que J48 y Naive Bayes, pero menos estable que ID3.

    Conclusi√≥n:
    ‚úÖ Podr√≠a mejorar con una mayor cantidad de vecinos (k=3 o k=5).

5. k-NN (k=3)
    Accuracy: 57.40% (mejor que IB1, pero peor que ID3).

    Interpretaci√≥n te√≥rica:

    - Usa los 3 vecinos m√°s cercanos para decidir la clase, lo que reduce el impacto de valores at√≠picos.
    - Mayor precisi√≥n en "Alto" que IB1 (28% vs. 33%), pero menor recall (80% vs. 54%).
    - Modelo m√°s estable que IB1, pero a√∫n no supera a ID3.

    Conclusi√≥n:
    ‚úÖ Mejor que IB1, pero podr√≠amos probar k=5 para ver si mejora a√∫n m√°s.

6. Regresi√≥n Log√≠stica
    Accuracy: 37.99% (similar a Naive Bayes).

    Interpretaci√≥n te√≥rica:

    - Funciona bien cuando hay una relaci√≥n lineal entre las variables y la salida, lo que no parece cumplirse aqu√≠.
    - Baja precisi√≥n en todas las clases excepto "Cero" (67% de precisi√≥n, pero 50% de recall).
    - Parece favorecer la clase mayoritaria, lo que hace que clases como "Alto" y "Medio" tengan precisi√≥n de 5% y 7% respectivamente.

    Conclusi√≥n:
    Modelo descartado. No es adecuado para este problema.

[VAMOS A PROCEDER A AJUSTAR LOS HIPERPAR√ÅMETROS DE LOS MODELOS M√ÅS PROMETEDORES]

Conclusi√≥n General de la Optimizaci√≥n

    ‚úÖ ID3 ya estaba en su mejor configuraci√≥n, por lo que la optimizaci√≥n no tuvo efecto.
    ‚ùå k-NN con weights="distance" no mejor√≥, e incluso empeor√≥ levemente.

¬øQu√© hacemos ahora?

    - Descartar m√°s ajustes en ID3 y probar Random Forest.
    - En k-NN, probar k=5 y k=7 para ver si mejora.
    - Pasar a la selecci√≥n de variables para ver si reduce el ruido y mejora los modelos.

Comparaci√≥n de Random Forest con √Årbol de Decisi√≥n (ID3)
¬øQu√© pas√≥?

    - Esper√°bamos que Random Forest superara ID3, pero su rendimiento es ligeramente peor.
    - Posible raz√≥n: Al usar max_depth=15, limitamos su capacidad de decisi√≥n.
    - Sin embargo, Random Forest sigue siendo m√°s robusto porque reduce el sobreajuste.

    Conclusi√≥n sobre Random Forest: ‚úÖ Tiene una mejor generalizaci√≥n que ID3, pero la precisi√≥n global no mejora.

Podr√≠amos probar Random Forest con max_depth=None para ver si mejora.

Comparaci√≥n de k-NN (k=3, k=5 y k=7)
¬øQu√© pas√≥?

    - Aumentar k a 5 y 7 no mejor√≥ el rendimiento, sino que lo redujo.
    - Esto indica que los puntos cercanos tienen m√°s informaci√≥n relevante, por lo que valores m√°s altos de k introducen ruido.
    - El mejor k sigue siendo k=3.

    üìä Conclusi√≥n sobre k-NN: ‚úÖ k=3 sigue siendo la mejor opci√≥n.
    ‚ùå k=5 y k=7 reducen la precisi√≥n, lo que indica que el modelo es m√°s sensible a vecinos cercanos.

Comparaci√≥n de Random Forest (max_depth=15 vs. max_depth=None)
¬øQu√© pas√≥?

    - Reducir max_depth a 15 mejoraba la generalizaci√≥n.
    - Sin l√≠mite de profundidad, el modelo se sobreajusta, perdiendo capacidad predictiva en datos nuevos.
    - Baj√≥ la precisi√≥n en todas las clases, especialmente en "Cero" y "Bajo".

    Conclusi√≥n:
    max_depth=None no es recomendable para este dataset.
    Random Forest con max_depth=15 sigue siendo mejor opci√≥n.


Comparaci√≥n con ID3 (√Årbol de Decisi√≥n)

    Conclusi√≥n General:
    
    1Ô∏è. ID3 sigue siendo el mejor modelo hasta ahora.
    2Ô∏è. Random Forest con max_depth=15 sigue siendo la mejor versi√≥n de Random Forest.
    3Ô∏è. max_depth=None causa sobreajuste y pierde capacidad predictiva.

¬øPodemos mejorar Random Forest?

- Podr√≠amos probar tres ajustes adicionales, pero hay razones para creer que no cambiar√°n radicalmente los resultados:

1Ô∏è. Aumentar n_estimators (n√∫mero de √°rboles)

¬øPor qu√© podr√≠a ayudar?

    - M√°s √°rboles pueden estabilizar la predicci√≥n y reducir la varianza.
    - Sin embargo, ya estamos usando 100 √°rboles, lo cual es un n√∫mero razonable.

¬øPor qu√© podr√≠a no servir?

    - El dataset no es tan grande, por lo que m√°s √°rboles pueden aumentar el tiempo de c√≥mputo sin mejorar la precisi√≥n.
    - ID3 ya est√° funcionando bien con un solo √°rbol, lo que indica que Random Forest no tiene una ventaja clara en esta tarea.

2Ô∏è. Probar otros criterios de divisi√≥n (criterion="gini" vs. "entropy")

¬øPor qu√© podr√≠a ayudar?

    - "gini" puede ser m√°s eficiente en algunos casos.
    - "entropy" (actualmente usado) es m√°s preciso en datasets con clases desbalanceadas.

¬øPor qu√© podr√≠a no servir?

    - Ya usamos "entropy" en ID3, que ha demostrado ser el mejor modelo.
    - Cambiar a "gini" rara vez produce mejoras significativas en problemas similares.

3Ô∏è. Probar min_samples_split y min_samples_leaf

¬øPor qu√© podr√≠a ayudar?

    - Ajustar estos valores puede hacer que el modelo aprenda menos ruido.

¬øPor qu√© podr√≠a no servir?

    - ID3 ya est√° funcionando bien sin necesidad de ajustes tan finos.
    - Si la selecci√≥n de variables mejora el dataset, el impacto en la precisi√≥n ser√° mayor que cualquier ajuste fino en Random Forest.

Reflexi√≥n Final: ¬øVale la pena seguir optimizando Random Forest?

‚ùå No, no tiene sentido seguir optimizando Random Forest en este punto.
‚úÖ Es m√°s estrat√©gico probar la selecci√≥n de variables y despu√©s ver si Random Forest mejora con un dataset m√°s limpio.
