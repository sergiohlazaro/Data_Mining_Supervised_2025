import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
print("\n")
print("1. Para empezar cargamos los datos y los prepararemos para el modelado:")
print(" - Hay que cargar el dataset y explorarlo, al explorarlo revisaremos valores nulos y duplicados y corregiremos estos si los hay.")
print(" - Por √∫ltimo, realizaremos un an√°lisis exploratorio de datos (EDA) para entender mejor los datos generando una serie de gr√°ficos.")
df = pd.read_csv("incidents.byCountryYr.csv")

print("\n")
print("El archivo contiene el siguiente n√∫mero de filas y columnas:")
print(df.shape)                                                                     # Muestra el n√∫mero de filas y columnas
print("-----------------------------------------------------------------------------------------------------------------------------------")

print("\nEl archivo contiene las siguientes columnas:")
print(df.columns)                                                                   # Lista los nombres de las columnas
print("-----------------------------------------------------------------------------------------------------------------------------------")

print("\nEl archivo contiene los siguientes tipos de datos:")
print(df.dtypes)                                                                    # Muestra los tipos de datos
print("-----------------------------------------------------------------------------------------------------------------------------------")

print("\nValores nulos por columna:\n", df.isnull().sum())                          # Verifica valores nulos
print("\nN√∫mero de filas duplicadas:", df.duplicated().sum())                       # Verifica duplicados

print("\nEstad√≠sticas descriptivas:")
print(df.describe())                                                                # Muestra estad√≠sticas descriptivas
print("-----------------------------------------------------------------------------------------------------------------------------------")

# --- AN√ÅLISIS EXPLORATORIO DE DATOS (EDA) ---

# 1Ô∏è. Distribuci√≥n de la variable "Freq" (Filtrar valores positivos)
df_filtered = df[df["Freq"] > 0]

plt.figure(figsize=(12, 5))
sns.histplot(df_filtered["Freq"], bins=50, kde=True)
plt.xlabel("N√∫mero de Incidentes")
plt.ylabel("Frecuencia")
plt.title("Distribuci√≥n de la Frecuencia de Incidentes por Pa√≠s y A√±o")
plt.grid(axis="y")

plt.savefig("imgs1/histograma_freq.png")
print("Gr√°fico guardado como 'histograma_freq.png'; √Åbrelo manualmente.")
print("-----------------------------------------------------------------------------------------------------------------------------------")

# 2Ô∏è. Transformaci√≥n logar√≠tmica de "Freq"
df["Freq_log"] = np.log1p(df["Freq"])                                               # log(1+Freq) para evitar log(0)

plt.figure(figsize=(12, 5))
sns.histplot(df["Freq_log"], bins=50, kde=True)
plt.xlabel("Logaritmo de Frecuencia de Incidentes")
plt.ylabel("Frecuencia")
plt.title("Distribuci√≥n Logar√≠tmica de la Frecuencia de Incidentes")
plt.grid(axis="y")

plt.savefig("imgs1/histograma_freq_log.png")
print("Gr√°fico guardado como 'histograma_freq_log.png'; √Åbrelo manualmente.")
print("-----------------------------------------------------------------------------------------------------------------------------------")

# 3Ô∏è. Convertir "Freq" en categor√≠as (Bajo, Medio, Alto)
                                                                                    # M√©todo m√°s robusto con `cut()` para evitar errores con valores repetidos
bins = [-1, 0, 10, 100, df["Freq"].max()]                                           # Definir cortes de categor√≠as
labels = ["Cero", "Bajo", "Medio", "Alto"]
df["Freq_category"] = pd.cut(df["Freq"], bins=bins, labels=labels)

print("\nDistribuci√≥n de la variable categorizada 'Freq_category':")
print(df["Freq_category"].value_counts())
print("-----------------------------------------------------------------------------------------------------------------------------------")

# 4Ô∏è. Normalizar "Freq" (Escalar entre 0 y 1)
scaler = MinMaxScaler()
df["Freq_scaled"] = scaler.fit_transform(df[["Freq"]])

print("\nEstad√≠sticas de la variable normalizada 'Freq_scaled':")
print(df[["Freq", "Freq_scaled"]].describe())
print("-----------------------------------------------------------------------------------------------------------------------------------")

# 5Ô∏è. Evoluci√≥n del n√∫mero de incidentes por a√±o
incidents_by_year = df.groupby("iyear")["Freq"].sum()

plt.figure(figsize=(12, 5))
plt.plot(incidents_by_year.index, incidents_by_year.values, marker="o", linestyle="-", color="b")
plt.xlabel("A√±o")
plt.ylabel("Total de Incidentes")
plt.title("Evoluci√≥n del N√∫mero de Incidentes por A√±o")
plt.grid(True)

plt.savefig("imgs1/evolucion_incidentes.png")
print("Gr√°fico guardado como 'evolucion_incidentes.png'; √Åbrelo manualmente.")
print("-----------------------------------------------------------------------------------------------------------------------------------")
print("\n¬°An√°lisis de datos completado!\n")
print("2. Ahora que hemos entendido los datos, podemos pasar a la fase de clasificaci√≥n supervisada:") 
print(" - Preparar los datos para el modelado.")
print(" - Entrenar los modelos de clasificaci√≥n (Naive Bayes, √Årboles de Decisi√≥n, k-NN, Regresi√≥n Log√≠stica).")
print(" - Evaluar el rendimiento de los modelos.\n")

print("\n3. Preparaci√≥n de los datos para el modelado:")
print(" - Selecci√≥n de variables predictoras y objetivo.")
print(" - Transformaci√≥n de variables categ√≥ricas en num√©ricas.")
print(" - Divisi√≥n del conjunto en entrenamiento y prueba.")

# 1. Seleccionar variables predictoras y objetivo
X = df[["iyear", "country_txt"]].copy()   # Variables predictoras
y = df["Freq_category"]  # Variable objetivo

# 2. Codificar "country_txt" a valores num√©ricos
label_encoder = LabelEncoder()
X["country_txt"] = label_encoder.fit_transform(X["country_txt"])

# 3. Dividir en conjunto de entrenamiento (80%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nDatos preparados:")
print(f" - Tama√±o del conjunto de entrenamiento: {X_train.shape}")
print(f" - Tama√±o del conjunto de prueba: {X_test.shape}")
print("-----------------------------------------------------------------------------------------------------------------------------------")

print("\n4. Entrenamiento de modelos de clasificaci√≥n:")
print(" - Entrenamos Naive Bayes, √Årbol de Decisi√≥n, k-NN y Regresi√≥n Log√≠stica.")
print(" - Evaluamos su rendimiento en el conjunto de prueba.")
print(" - ERRORES que surgieron y se aplico: Balanceo de clases con SMOTE.")
print(" - ERRORES que surgieron y se aplico: Aumentamos iteraciones en Regresi√≥n Log√≠stica.")
print(" - ERRORES que surgieron y se aplico: Evaluamos modelos con matriz de confusi√≥n.")

# 1Ô∏è. Entrenar **Naive Bayes**
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)
nb_preds = nb_model.predict(X_test)

# 2Ô∏è. Entrenar **√Årbol de Decisi√≥n**
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
dt_preds = dt_model.predict(X_test)

# 3Ô∏è. Entrenar **k-NN (k=5)**
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)
knn_preds = knn_model.predict(X_test)

# 4Ô∏è. Entrenar **Regresi√≥n Log√≠stica**
lr_model = LogisticRegression(max_iter=200, solver="lbfgs", multi_class="multinomial")
lr_model.fit(X_train, y_train)
lr_preds = lr_model.predict(X_test)

# 5. Evaluaci√≥n de precisi√≥n
print("\nResultados de los modelos:")
print(f"üîπ Naive Bayes Accuracy: {accuracy_score(y_test, nb_preds):.4f}")
print(f"üîπ √Årbol de Decisi√≥n Accuracy: {accuracy_score(y_test, dt_preds):.4f}")
print(f"üîπ k-NN Accuracy: {accuracy_score(y_test, knn_preds):.4f}")
print(f"üîπ Regresi√≥n Log√≠stica Accuracy: {accuracy_score(y_test, lr_preds):.4f}")

print("\nClasificaci√≥n detallada para Naive Bayes:")
print(classification_report(y_test, nb_preds))

print("\nClasificaci√≥n detallada para √Årbol de Decisi√≥n:")
print(classification_report(y_test, dt_preds))

print("\nClasificaci√≥n detallada para k-NN:")
print(classification_report(y_test, knn_preds))

print("\nClasificaci√≥n detallada para Regresi√≥n Log√≠stica:")
print(classification_report(y_test, lr_preds))

print("-----------------------------------------------------------------------------------------------------------------------------------")
print("Surgen varios problemas con este script:")
print("1. Regresi√≥n log√≠stica no converge [lbfgs failed to converge (status=1): STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT]: soluci√≥n, aumentar max_iter a 1000 o m√°s para permitir m√°s interacciones")
print("2. Naive Bayes y Regresi√≥n Log√≠stica solo predicen la clase mayoritaria (Cero),lo que indica que los modelos no est√°n aprendiendo correctamente, la distribuci√≥n de clases es desbalanceada, con demasiados datos en la clase Cero: soluci√≥n, balancear las clases con SMOTE (aplicar balanceo de clases (undersampling, oversampling o t√©cnicas como SMOTE))")
print("3. Advertencias de precisi√≥n indefinida (UndefinedMetricWarning) ocurre porque ciertas clases nunca son predichas, en la clasificaci√≥n detallada; soluci√≥n, establecer zero_division=0 en classification_report para evitar advertencias.")